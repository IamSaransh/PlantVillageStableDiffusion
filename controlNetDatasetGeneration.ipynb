{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Path to your JSONL file\n",
    "file_path = \"C:\\workspace\\Research\\Diffusion\\PlantAugmentation\\controlnet-dataset\\metadata.jsonl\"\n",
    "\n",
    "# Initialize an empty list to store the dictionaries\n",
    "data = []\n",
    "\n",
    "# Open and read the JSONL file\n",
    "with open(file_path, 'r') as f:\n",
    "    for line in f:\n",
    "        # Parse each line as a JSON object and append it to the list\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "# Now 'data' is a list of dictionaries, each corresponding to one line in the JSONL file\n",
    "# for entry in data:\n",
    "#     print(entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converted canny images for 20638 images\n"
     ]
    }
   ],
   "source": [
    "folder_name=\"C:\\workspace\\Research\\Diffusion\\PlantAugmentation\\controlnet-dataset\"\n",
    "\n",
    "i = 0\n",
    "for entry in data:\n",
    "    i+=1\n",
    "    file_name = entry['file_name']\n",
    "    img_path = os.path.join(folder_name, file_name)\n",
    "\n",
    "    grey_img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Convert to grayscale\n",
    "    blur_img = cv2.GaussianBlur(grey_img, (5, 5), 0)\n",
    "\n",
    "    # Apply Canny edge detection\n",
    "    img = cv2.adaptiveThreshold(blur_img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, blockSize=61, C=15)\n",
    "    edges = cv2.Canny(img, threshold1=50, threshold2=170)  # Adjust thresholds as needed\n",
    "    output_path = os.path.join(folder_name, f\"edges_{file_name}\")  # Save with a new name or add a prefix\n",
    "    cv2.imwrite(output_path, edges)\n",
    "    entry['canny_entry'] = output_path\n",
    "\n",
    "print(f\"converted canny images for {i} images\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41276"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(folder_name, \"metadata.jsonl\"), 'w') as file:\n",
    "    json.dump(data, file, indent=4)  # Writes dictionary to file with pretty formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to C:\\Users\\saran\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(token='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')\n",
    "from datasets import load_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.push_to_hub(\"ButterChicken98/conrtolnet-plantvillage-improved-captions-canny-images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from datasets import Dataset,DatasetDict\n",
    "from PIL import Image\n",
    "import cv2\n",
    "folder_name=\"C:\\workspace\\Research\\Diffusion\\PlantAugmentation\\controlnet-dataset\"\n",
    "# Path to your images folder and metadata file\n",
    "image_folder = folder_name  # Replace with your folder path\n",
    "metadata_file = os.path.join(image_folder,\"metadata.jsonl\")\n",
    "\n",
    "from io import BytesIO\n",
    "def image_to_bytes(image):\n",
    "    with BytesIO() as byte_io:\n",
    "        image.save(byte_io, format='PNG')\n",
    "        return byte_io.getvalue()\n",
    "    \n",
    "# Function to load and preprocess an image\n",
    "def load_image(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    img = img.convert(\"RGB\")  # Convert to RGB\n",
    "    return img\n",
    "\n",
    "# Function to load and preprocess the canny edges\n",
    "def load_canny_edges(canny_path):\n",
    "    img = cv2.imread(canny_path, cv2.IMREAD_GRAYSCALE)\n",
    "    return img\n",
    "def load_canny_edges2(canny_path):\n",
    "    img = Image.open(canny_path)\n",
    "    img = img.convert(\"L\")\n",
    "    return img\n",
    "\n",
    "# Read metadata and load images\n",
    "hf_data = {\n",
    "    'image': [],\n",
    "    'canny_edges': [],\n",
    "    'caption': [],\n",
    "    'captions': []\n",
    "}\n",
    "i=0\n",
    "with open(metadata_file, 'r') as f:\n",
    "    for line in f:\n",
    "        i+=1\n",
    "        entry = json.loads(line.strip())\n",
    "\n",
    "        # Construct the paths for the image and Canny edges\n",
    "        image_path = os.path.join(image_folder, entry[\"file_name\"])\n",
    "        canny_path = os.path.join(image_folder, entry[\"canny_entry\"])\n",
    "\n",
    "        # Load the image and Canny edges\n",
    "        image = load_image(image_path)\n",
    "        canny_edges = load_canny_edges2(canny_path)\n",
    "\n",
    "        # Store data for Hugging Face Dataset\n",
    "        data.append({\n",
    "            \"image\": image,\n",
    "            \"canny_edges\": canny_edges,\n",
    "            \"caption\": entry[\"caption\"],\n",
    "            \"captions\": entry[\"captions\"]\n",
    "        })\n",
    "        hf_data['image'].append(image)  # Save image as bytes for the dataset\n",
    "        hf_data['canny_edges'].append(canny_edges)  # Convert numpy array to list for canny edges\n",
    "        hf_data['caption'].append(entry['caption'])\n",
    "        hf_data['captions'].append(entry['captions'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=256x256 at 0x17144DD06A0>, 'canny_edges': <PIL.PngImagePlugin.PngImageFile image mode=L size=256x256 at 0x17144DD0400>, 'caption': 'Pepper bell Bacterial spot', 'captions': ['A bell pepper leaf showing small, dark, water-soaked spots typical of bacterial spot disease.', 'A bell pepper leaf infected with Xanthomonas campestris, displaying characteristic lesions with yellow halos.', 'A healthy green bell pepper leaf with scattered dark spots, photographed in natural light.', 'A high-resolution image of a bell pepper leaf affected by bacterial spot, designed for plant disease classification.']}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d188d2b1ae454a118d46f24920918a40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/6 shards):   0%|          | 0/20638 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create Hugging Face dataset from the dictionary\n",
    "dataset = Dataset.from_dict(hf_data)\n",
    "\n",
    "# Print a sample from the dataset\n",
    "print(dataset[0])\n",
    "\n",
    "# # Save the dataset to disk (optional)\n",
    "dataset.save_to_disk('plant_disease_dataset_canny_edges_with_prompt_engineering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4517fd90f2924d059c2a8d3ffd65443f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db06020f0af84ff5bec3f373d55b389f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3440 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff4c30dfaaa14e7e99312b407b8d3719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/35 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e96d7e0a658423c95aadf0e62d70467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3440 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0e1077224b24f01a477f94ab81a15aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/35 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afd3bf4d1e7a426195fe7e00976ad22b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3440 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5271b3a815d48689799a147cf12b655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/35 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bb74dca2ce14528aa4b64703003dd12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3440 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "627673b8376944ce8fb447c981524f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/35 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8dd87721cd04da9b7352545d700b283",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3439 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f4667f0b9d64a75bc952dbc95dd41d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/35 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46f7c536274145d8b341c3e98fd861f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3439 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4672fe9e40744922bd996d6755134b77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/35 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/ButterChicken98/test-controlnet-full/commit/e548a2e8f185e6ff4db7de265ce3c2960ea01703', commit_message='Upload dataset', commit_description='', oid='e548a2e8f185e6ff4db7de265ce3c2960ea01703', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/ButterChicken98/test-controlnet-full', endpoint='https://huggingface.co', repo_type='dataset', repo_id='ButterChicken98/test-controlnet-full'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset,DatasetDict\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': dataset,\n",
    "    # 'test': test_dataset  # If you have a test set\n",
    "})\n",
    "dataset_dict.push_to_hub(\"ButterChicken98/test-controlnet-full\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colab-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
